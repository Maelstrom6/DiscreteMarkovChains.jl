var documenterSearchIndex = {"docs":
[{"location":"functions/probability/#Probability-Functions","page":"Probability Functions","title":"Probability Functions","text":"","category":"section"},{"location":"functions/probability/#Contents","page":"Probability Functions","title":"Contents","text":"","category":"section"},{"location":"functions/probability/","page":"Probability Functions","title":"Probability Functions","text":"Pages = [\"probability.md\"]","category":"page"},{"location":"functions/probability/#Index","page":"Probability Functions","title":"Index","text":"","category":"section"},{"location":"functions/probability/","page":"Probability Functions","title":"Probability Functions","text":"Pages = [\"probability.md\"]","category":"page"},{"location":"functions/probability/#Documentation","page":"Probability Functions","title":"Documentation","text":"","category":"section"},{"location":"functions/probability/","page":"Probability Functions","title":"Probability Functions","text":"DiscreteMarkovChains.stationary_distribution\nDiscreteMarkovChains.fundamental_matrix\nDiscreteMarkovChains.exit_probabilities\nDiscreteMarkovChains.first_passage_probabilities","category":"page"},{"location":"functions/probability/#DiscreteMarkovChains.stationary_distribution","page":"Probability Functions","title":"DiscreteMarkovChains.stationary_distribution","text":"stationary_distribution(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA column vector, w, that satisfies the equation wT = w.\n\n\n\n\n\n","category":"function"},{"location":"functions/probability/#DiscreteMarkovChains.fundamental_matrix","page":"Probability Functions","title":"DiscreteMarkovChains.fundamental_matrix","text":"fundamental_matrix(x)\n\nThe fundamental matrix of a markov chain is defined to be (I-C)^-1  where C is the sub-transition matrix that takes transient states  to transient states.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nThe fundamental matrix of the Markov chain\n\n\n\n\n\n","category":"function"},{"location":"functions/probability/#DiscreteMarkovChains.exit_probabilities","page":"Probability Functions","title":"DiscreteMarkovChains.exit_probabilities","text":"exit_probabilities(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nAn array where element i j is the probability that transient  state i will enter recurrent state j on its first step  out of the transient states. That is, e_ij.\n\n\n\n\n\n","category":"function"},{"location":"functions/probability/#DiscreteMarkovChains.first_passage_probabilities","page":"Probability Functions","title":"DiscreteMarkovChains.first_passage_probabilities","text":"first_passage_probabilities(x, t, i=missing, j=missing)\n\nThis is the probability that the process enters state j  for the first time at time t given that the process started  in state i at time 0. That is, f^(t)_ij. If no i  or j is given, then it will return a matrix instead with  entries f^(t)_ij for i and j in the state space of x.\n\nWhy Do We Use A Slow Algorithm?\n\nSo that t can be symbolic if nessesary. That is, if symbolic math libraries want to use this library, it will pose no hassle.\n\nParameters\n\nx: some kind of Markov chain.\nt: the time to calculate the first passage probability.\ni: the state that the prcess starts in.\nj: the state that the process must reach for the first time.\n\nReturns\n\nA scalar value or a matrix depending on whether i and j are given.\n\nReferences\n\nhttps://scholar.uwindsor.ca/cgi/viewcontent.cgi?article=1125&context=major-papers http://maths.dur.ac.uk/stats/courses/ProbMC2H/_files/handouts/1516MarkovChains2H.pdf\n\n\n\n\n\n","category":"function"},{"location":"functions/basic/#Core-Types","page":"Core Types","title":"Core Types","text":"","category":"section"},{"location":"functions/basic/#Contents","page":"Core Types","title":"Contents","text":"","category":"section"},{"location":"functions/basic/","page":"Core Types","title":"Core Types","text":"Pages = [\"basic.md\"]","category":"page"},{"location":"functions/basic/#Index","page":"Core Types","title":"Index","text":"","category":"section"},{"location":"functions/basic/","page":"Core Types","title":"Core Types","text":"Pages = [\"basic.md\"]","category":"page"},{"location":"functions/basic/#Documentation","page":"Core Types","title":"Documentation","text":"","category":"section"},{"location":"functions/basic/","page":"Core Types","title":"Core Types","text":"The main type is DiscreteMarkovChain:","category":"page"},{"location":"functions/basic/","page":"Core Types","title":"Core Types","text":"DiscreteMarkovChains.DiscreteMarkovChain\nDiscreteMarkovChains.state_space\nDiscreteMarkovChains.transition_matrix","category":"page"},{"location":"functions/basic/#DiscreteMarkovChains.DiscreteMarkovChain","page":"Core Types","title":"DiscreteMarkovChains.DiscreteMarkovChain","text":"DiscreteMarkovChain(transition_matrix)\nDiscreteMarkovChain(state_space, transition_matrix)\n\nCreates a new discrete Markov chain object.\n\nParameters\n\nstate_space: The names of the states that make up the Markov chain.\ntransition_matrix: The single step transition probability matrix.\n\nExamples\n\nThe following shows a basic Sunny-Cloudy-Rainy weather model.\n\nusing DiscreteMarkovChains\nT = [\n    0.9 0.1 0;\n    0.5 0.2 0.3;\n    0.1 0.4 0.5\n]\nX = DiscreteMarkovChain([\"Sunny\", \"Cloudy\", \"Rainy\"], T)\nprintln(state_space(X))\n\n# output\n\n[\"Sunny\", \"Cloudy\", \"Rainy\"]\n\nprintln(transition_matrix(X))\n\n# output\n\n[0.9 0.1 0.0; 0.5 0.2 0.3; 0.1 0.4 0.5]\n\nReferences\n\nhttps://en.wikipedia.org/wiki/Markovchain#Discrete-timeMarkovchain https://www.dartmouth.edu/~chance/teachingaids/booksarticles/probabilitybook/Chapter11.pdf\n\n\n\n\n\n","category":"type"},{"location":"functions/basic/#DiscreteMarkovChains.state_space","page":"Core Types","title":"DiscreteMarkovChains.state_space","text":"state_space(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nThe state space of the Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"functions/basic/#DiscreteMarkovChains.transition_matrix","page":"Core Types","title":"DiscreteMarkovChains.transition_matrix","text":"transition_matrix(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nThe transition matrix of the Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"DiscreteMarkovChains should be up on Julia's package registry.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Simply type","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Import Pkg\nPkg.add(\"DiscreteMarkovChains\")","category":"page"},{"location":"functions/simple/#Simple-Functions","page":"Simple Functions","title":"Simple Functions","text":"","category":"section"},{"location":"functions/simple/#Contents","page":"Simple Functions","title":"Contents","text":"","category":"section"},{"location":"functions/simple/","page":"Simple Functions","title":"Simple Functions","text":"Pages = [\"simple.md\"]","category":"page"},{"location":"functions/simple/#Index","page":"Simple Functions","title":"Index","text":"","category":"section"},{"location":"functions/simple/","page":"Simple Functions","title":"Simple Functions","text":"Pages = [\"simple.md\"]","category":"page"},{"location":"functions/simple/#Documentation","page":"Simple Functions","title":"Documentation","text":"","category":"section"},{"location":"functions/simple/","page":"Simple Functions","title":"Simple Functions","text":"DiscreteMarkovChains.is_regular\nDiscreteMarkovChains.is_ergodic\nDiscreteMarkovChains.is_absorbing","category":"page"},{"location":"functions/simple/#DiscreteMarkovChains.is_regular","page":"Simple Functions","title":"DiscreteMarkovChains.is_regular","text":"is_regular(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\ntrue if the Markov chain, x, is regular.\n\n\n\n\n\n","category":"function"},{"location":"functions/simple/#DiscreteMarkovChains.is_ergodic","page":"Simple Functions","title":"DiscreteMarkovChains.is_ergodic","text":"is_ergodic(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\ntrue if the Markov chain, x, is ergodic. This is, if every state can be accessed from every other state. Another term for this is irreducible.\n\n\n\n\n\n","category":"function"},{"location":"functions/simple/#DiscreteMarkovChains.is_absorbing","page":"Simple Functions","title":"DiscreteMarkovChains.is_absorbing","text":"is_absorbing(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\ntrue if the Markov chain, x, is an absorbing chain. So the process is guarenteed to be absorbed eventually.\n\n\n\n\n\n","category":"function"},{"location":"functions/mean/#Mean-Time-Functions","page":"Mean Time Functions","title":"Mean Time Functions","text":"","category":"section"},{"location":"functions/mean/#Contents","page":"Mean Time Functions","title":"Contents","text":"","category":"section"},{"location":"functions/mean/","page":"Mean Time Functions","title":"Mean Time Functions","text":"Pages = [\"mean.md\"]","category":"page"},{"location":"functions/mean/#Index","page":"Mean Time Functions","title":"Index","text":"","category":"section"},{"location":"functions/mean/","page":"Mean Time Functions","title":"Mean Time Functions","text":"Pages = [\"mean.md\"]","category":"page"},{"location":"functions/mean/#Documentation","page":"Mean Time Functions","title":"Documentation","text":"","category":"section"},{"location":"functions/mean/","page":"Mean Time Functions","title":"Mean Time Functions","text":"DiscreteMarkovChains.expected_time_to_absorption\nDiscreteMarkovChains.mean_recurrence_time\nDiscreteMarkovChains.mean_first_passage_time","category":"page"},{"location":"functions/mean/#DiscreteMarkovChains.expected_time_to_absorption","page":"Mean Time Functions","title":"DiscreteMarkovChains.expected_time_to_absorption","text":"expected_time_to_absorption(x)\n\nThe expected number of steps that the process will take while in  the transient super class given that the process started in state i.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA 1D array where element i is the total number of revisits to  transient state i before leaving the transient super class.\n\nNote\n\nIt is advised to have x in canonical form already. This is to avoid confusion of what states make up each  element of the array ouput.\n\n\n\n\n\n","category":"function"},{"location":"functions/mean/#DiscreteMarkovChains.mean_recurrence_time","page":"Mean Time Functions","title":"DiscreteMarkovChains.mean_recurrence_time","text":"mean_recurrence_time(x)\n\nThis is the expected number of steps for the process to  return to state i given that the process started in state i.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA 1D array where the ith entry is the mean recurrence time of state i.\n\nNote\n\nx must be irreducible (i.e. ergodic).\n\n\n\n\n\n","category":"function"},{"location":"functions/mean/#DiscreteMarkovChains.mean_first_passage_time","page":"Mean Time Functions","title":"DiscreteMarkovChains.mean_first_passage_time","text":"mean_first_passage_time(x)\n\nThis is the expected number of steps for the process to  reach state j given that the process started in state i.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA matrix where the i,jth entry is the mean recurrence time of state i.  Diagonal elements are 0.  The diagonals would have represented the mean recurrence time.\n\n\n\n\n\n","category":"function"},{"location":"#DiscreteMarkovChains","page":"Home","title":"DiscreteMarkovChains","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = DiscreteMarkovChains","category":"page"},{"location":"","page":"Home","title":"Home","text":"DiscreteMarkovChains is a package that supports various functions relating to discrete Markov chains. In particular, it deals with discrete-time discrete-space time-homogenous finite Markov chains.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A 100% pure-Julia stack library for functions and queries related to discrete Markov chains.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DiscreteMarkovChains should be up on Julia's package registry.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Simply type ] add DiscreteMarkovChains into the Julia REPL.","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the documentation hosted on GitHub Pages.","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We want to find out if this chain is an absorbing chain.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using DiscreteMarkovChains\n\ntransition_matrix = [\n    0.0 1.0 0.0;\n    0.5 0.0 0.5;\n    0.0 1.0 0.0;\n]\nchain = DiscreteMarkovChain(transition_matrix)\nis_absorbing(chain)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Let's try find the communication classes, see if they are recurrent and what their periodicity is.","category":"page"},{"location":"","page":"Home","title":"Home","text":"periodicities(chain)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This means that we have one communication class with 3 recurrent states. Their periodicity is 2.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Since we have a single communication class, we can calculate the mean recurrence times.","category":"page"},{"location":"","page":"Home","title":"Home","text":"mean_recurrence_time(chain)","category":"page"},{"location":"","page":"Home","title":"Home","text":"So the first and third states take an average of 4 time steps to return to itself. The second state takes an average of 2 steps to return to itself.","category":"page"},{"location":"#Authors","page":"Home","title":"Authors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Chris du Plessis","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MIT","category":"page"},{"location":"functions/internal/#Internal-Functions","page":"Internal Functions","title":"Internal Functions","text":"","category":"section"},{"location":"functions/internal/","page":"Internal Functions","title":"Internal Functions","text":"These functions are not intended to be used by you, the user.","category":"page"},{"location":"functions/internal/#Contents","page":"Internal Functions","title":"Contents","text":"","category":"section"},{"location":"functions/internal/","page":"Internal Functions","title":"Internal Functions","text":"Pages = [\"internal.md\"]","category":"page"},{"location":"functions/internal/#Index","page":"Internal Functions","title":"Index","text":"","category":"section"},{"location":"functions/internal/","page":"Internal Functions","title":"Internal Functions","text":"Pages = [\"internal.md\"]","category":"page"},{"location":"functions/internal/#Documentation","page":"Internal Functions","title":"Documentation","text":"","category":"section"},{"location":"functions/internal/","page":"Internal Functions","title":"Internal Functions","text":"The main type is DiscreteMarkovChain:","category":"page"},{"location":"functions/internal/","page":"Internal Functions","title":"Internal Functions","text":"DiscreteMarkovChains.strongly_connected_components\nDiscreteMarkovChains.breadth_first_search\n\nDiscreteMarkovChains.digraph\n\nDiscreteMarkovChains.state_index\nDiscreteMarkovChains.is_row_stochastic","category":"page"},{"location":"functions/internal/#DiscreteMarkovChains.strongly_connected_components","page":"Internal Functions","title":"DiscreteMarkovChains.strongly_connected_components","text":"strongly_connected_components(V::Array, E::Array{Tuple})\n\nStrongly connected components of a directed graph in reverse topological order. Translated from sympy/utilities/iteratbles.py/stronglyconnectedcomponents.\n\n\n\n\n\n","category":"function"},{"location":"functions/internal/#DiscreteMarkovChains.breadth_first_search","page":"Internal Functions","title":"DiscreteMarkovChains.breadth_first_search","text":"Computes the period of an irreducible transition matrix T must be a 2D array\n\n\n\n\n\n","category":"function"},{"location":"functions/internal/#DiscreteMarkovChains.digraph","page":"Internal Functions","title":"DiscreteMarkovChains.digraph","text":"digraph(x)\n\nCreates a digraph (directed graph) representation of a Markov chain.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA 1D array of 2-tuples. An element (i j) is in the array  iff the transition matrix at ij is nonzero.\n\n\n\n\n\n","category":"function"},{"location":"functions/internal/#DiscreteMarkovChains.state_index","page":"Internal Functions","title":"DiscreteMarkovChains.state_index","text":"state_index(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA dictionary mapping each state in a Markov chain to its position in the state space.  It is essentially the inverse of state_space(x).\n\n\n\n\n\n","category":"function"},{"location":"functions/internal/#DiscreteMarkovChains.is_row_stochastic","page":"Internal Functions","title":"DiscreteMarkovChains.is_row_stochastic","text":"is_row_stochastic(mat, row_sum=1)\n\nTests whether a matrix, x, is row stochasitc. The desired sum of each row can be specified as well.\n\nParameters\n\nmat: a matrix that we want to check.\nrow_sum: the desired value that each row should total to.\n\nReturns\n\ntrue if the given matrix, mat, is row-stochasitc.\n\n\n\n\n\n","category":"function"},{"location":"functions/communication/#Communication-Functions","page":"Communication Functions","title":"Communication Functions","text":"","category":"section"},{"location":"functions/communication/#Contents","page":"Communication Functions","title":"Contents","text":"","category":"section"},{"location":"functions/communication/","page":"Communication Functions","title":"Communication Functions","text":"Pages = [\"communication.md\"]","category":"page"},{"location":"functions/communication/#Index","page":"Communication Functions","title":"Index","text":"","category":"section"},{"location":"functions/communication/","page":"Communication Functions","title":"Communication Functions","text":"Pages = [\"communication.md\"]","category":"page"},{"location":"functions/communication/#Documentation","page":"Communication Functions","title":"Documentation","text":"","category":"section"},{"location":"functions/communication/","page":"Communication Functions","title":"Communication Functions","text":"DiscreteMarkovChains.communication_classes\nDiscreteMarkovChains.periodicities\nDiscreteMarkovChains.decompose\nDiscreteMarkovChains.canonical_form","category":"page"},{"location":"functions/communication/#DiscreteMarkovChains.communication_classes","page":"Communication Functions","title":"DiscreteMarkovChains.communication_classes","text":"communication_classes(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA tuple containing 2 arrays. \n\nThis first array contains C arrays which store the states that communicate. \nThe second array is an array of Bool where the ith value is true if the  ith communication class is recurrent. \n\n\n\n\n\n","category":"function"},{"location":"functions/communication/#DiscreteMarkovChains.periodicities","page":"Communication Functions","title":"DiscreteMarkovChains.periodicities","text":"periodicities(x::AbstractDiscreteMarkovChain)\n\nA more advanced version of communication_classes  designed for discrete Markov chains. It is the same as  communication_classes but it returns periodicities as well.\n\nParameters\n\nx: some kind of discrete Markov chain.\n\nReturns\n\nA tuple containing 3 arrays. \n\nThis first array contains C arrays which store the states that communicate. \nThe second array is an array of Bool where the ith value is true if the  ith communication class is recurrent. \nThe third array is the periodicity of each communication class.\n\n\n\n\n\n","category":"function"},{"location":"functions/communication/#DiscreteMarkovChains.decompose","page":"Communication Functions","title":"DiscreteMarkovChains.decompose","text":"decompose(x)\n\nAll transition matrices can be reordered so that we have\n\nT = beginpmatrix\nA  0\nB  C\nendpmatrix\n\nWhere A, B and C are as described below.  0 is a matrix of zeros.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA tuple of four values\n\nstates: the first value is an array of the new states.\nA: the second value is a matrix of recurrent states to recurrent states.\nB: the third value is a matrix of transient states to recurrent states.\nC: the fourth value is a matrix of transient to transient states.\n\n\n\n\n\n","category":"function"},{"location":"functions/communication/#DiscreteMarkovChains.canonical_form","page":"Communication Functions","title":"DiscreteMarkovChains.canonical_form","text":"canonical_form(x)\n\nReorders the states of the transition matrix of x so that  recurrent states appear first and transient states appear last.\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA tuple with the new states and the new transition matrix.\n\n\n\n\n\n","category":"function"}]
}
