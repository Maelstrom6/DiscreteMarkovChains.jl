var documenterSearchIndex = {"docs":
[{"location":"introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"introduction/#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"DiscreteMarkovChains should be up on Julia's package registry.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Simply type","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Import Pkg\nPkg.add(\"DiscreteMarkovChains\")","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"introduction/#Core-Types","page":"Introduction","title":"Core Types","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The main type is DiscreteMarkovChain:","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"DiscreteMarkovChains.DiscreteMarkovChain\nDiscreteMarkovChains.state_space\nDiscreteMarkovChains.transition_matrix","category":"page"},{"location":"introduction/#DiscreteMarkovChains.DiscreteMarkovChain","page":"Introduction","title":"DiscreteMarkovChains.DiscreteMarkovChain","text":"DiscreteMarkovChain(state_space, transition_matrix)\n\nCreates a new discrete Markov chain object.\n\nParameters\n\nstate_space: The names of the states that make up the Markov chain.\ntransition_matrix: The single step transition probability matrix.\n\nExamples\n\nThe following shows a basic Sunny-Cloudy-Rainy weather model.\n\nusing DiscreteMarkovChains\nT = [\n     0.9 0.1 0;\n     0.5 0.2 0.3;\n     0.1 0.4 0.5\n    ]\nX = DiscreteMarkovChain([\"Sunny\", \"Cloudy\", \"Rainy\"], T)\nprint(state_space(X))\n\n# output\n\n[\"Sunny\", \"Cloudy\", \"Rainy\"]\n\n\n\n\n\n","category":"type"},{"location":"introduction/#DiscreteMarkovChains.state_space","page":"Introduction","title":"DiscreteMarkovChains.state_space","text":"state_space(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nThe state space of a Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.transition_matrix","page":"Introduction","title":"DiscreteMarkovChains.transition_matrix","text":"transition_matrix(x)\n\nReturns\n\nThe transition matrix of a Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#Simple-Functions","page":"Introduction","title":"Simple Functions","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"DiscreteMarkovChains.is_regular\nDiscreteMarkovChains.is_ergodic\nDiscreteMarkovChains.is_absorbing","category":"page"},{"location":"introduction/#DiscreteMarkovChains.is_regular","page":"Introduction","title":"DiscreteMarkovChains.is_regular","text":"is_regular(x)\n\nReturns\n\ntrue if the Markov chain, x, is regular.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.is_ergodic","page":"Introduction","title":"DiscreteMarkovChains.is_ergodic","text":"is_ergodic(x)\n\nReturns\n\ntrue if the Markov chain, x, is ergodic. This is, if every state can be accessed from every other state. Another term for this is irreducible.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.is_absorbing","page":"Introduction","title":"DiscreteMarkovChains.is_absorbing","text":"is_absorbing(x)\n\nReturns\n\ntrue if the Markov chain, x, is an absorbing chain. So the process is guarenteed to be absorbed eventually.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#Communicaton-Functions","page":"Introduction","title":"Communicaton Functions","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"DiscreteMarkovChains.communication_classes\nDiscreteMarkovChains.periodicities\nDiscreteMarkovChains.decompose\nDiscreteMarkovChains.canonical_form","category":"page"},{"location":"introduction/#DiscreteMarkovChains.communication_classes","page":"Introduction","title":"DiscreteMarkovChains.communication_classes","text":"communication_classes(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA tuple containing 2 arrays. \n\nThis first array contains C arrays which store the states that communicate. \nThe second array is an array of Bool where the ith value is true if the ith communication class is recurrent. \n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.periodicities","page":"Introduction","title":"DiscreteMarkovChains.periodicities","text":"periodicities(x::AbstractDiscreteMarkovChain)\n\nA more advanced version of communication_classes  designed for discrete Markov chains. It is the same as  communication_classes but it returns periodicities as well.\n\nParameters\n\nx: some kind of discrete Markov chain.\n\nReturns\n\nA tuple containing 3 arrays. \n\nThis first array contains C arrays which store the states that communicate. \nThe second array is an array of Bool where the ith value is true if the ith communication class is recurrent. \nThe third array is the periodicity of each communication class.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.decompose","page":"Introduction","title":"DiscreteMarkovChains.decompose","text":"decompose(x)\n\nParameters\n\nx: some kind of Markov chain.\n\nReturns\n\nA tuple of four values\n\nThe first value is an array of the new states.\nThe second value is a matrix of recurrent states to recurrent states.\nThe third value is a matrix of transient states to recurrent states.\nThe fourth value is a matrix of transient to transient states.\n\n\n\n\n\n","category":"function"},{"location":"introduction/#DiscreteMarkovChains.canonical_form","page":"Introduction","title":"DiscreteMarkovChains.canonical_form","text":"canonical_form(x)\n\nReorders the states of the transition matrix of x so that we have recurrent states first and transient states last.\n\nReturns\n\nA tuple with the new states and the new transition matrix.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = DiscreteMarkovChains","category":"page"},{"location":"#DiscreteMarkovChains","page":"Home","title":"DiscreteMarkovChains","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DiscreteMarkovChains is a package that supports various functions relating to discrete Markov chains. In particular, it deals with discrete-time discrete-space time-homogenous finite Markov chains.","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Introduction","category":"page"},{"location":"#Authors","page":"Home","title":"Authors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Chris du Plessis","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MIT","category":"page"}]
}
